{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Introduction\nIn this competition, The goal is to correctly identify digits from a dataset of tens of thousands of handwritten images. \n\n## Dataset\nFor this competition, we will be using the popular MNIST database. It is a collection of 70.000 handwritten digits split into training and test set of 42.000 and 28.000 images respectively."},{"metadata":{},"cell_type":"markdown","source":"## Setting up the Environment\nWe will be using PyTorch to train a convolutional neural network to recognize MNIST's handwritten digits."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\nfrom PIL import Image\nfrom sklearn.model_selection import train_test_split\nimport math\nimport copy\nimport time\n\nimport torch\nimport torchvision\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision import transforms\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom torchvision.utils import make_grid\n\n#neural net imports\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.autograd import Variable\n\n%matplotlib inline\nprint(torch.__version__)","execution_count":1,"outputs":[{"output_type":"stream","text":"1.2.0\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"## Preparing the Dataset\n\nwe'll define the hyperparameters we'll be using for the experiment. Here the number of epochs defines how many times we'll loop over the complete training dataset, while learning_rate is the hyperparameter for the optimizer we'll be using later on.\n\nWe read both training and test set into dataframe then we split our training dataset into train and valid dataset in order to train and test our model. Train/Valid ratio is 15%."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"random_seed = 42\ntorch.backends.cudnn.enabled = False\ntorch.manual_seed(random_seed)\n\n# Load the data\ntrain_df = pd.read_csv(\"../input/digit-recognizer/train.csv\")\ntest_df = pd.read_csv(\"../input/digit-recognizer/test.csv\")\n\ny = train_df[\"label\"]\nx = train_df.drop(\"label\", axis = 1)\n\n#Split training data into Train and validation set\nX_train, X_valid, y_train, y_valid = train_test_split(x, y, test_size=0.15, shuffle=True)\n\nnum_epoch = 25\nbatch_size_train = 32\nbatch_size_test = 32\nlearning_rate = 0.002\nmomentum = 0.9\nlog_interval = 100","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head()","execution_count":3,"outputs":[{"output_type":"execute_result","execution_count":3,"data":{"text/plain":"   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n0      1       0       0       0       0       0       0       0       0   \n1      0       0       0       0       0       0       0       0       0   \n2      1       0       0       0       0       0       0       0       0   \n3      4       0       0       0       0       0       0       0       0   \n4      0       0       0       0       0       0       0       0       0   \n\n   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n0       0  ...         0         0         0         0         0         0   \n1       0  ...         0         0         0         0         0         0   \n2       0  ...         0         0         0         0         0         0   \n3       0  ...         0         0         0         0         0         0   \n4       0  ...         0         0         0         0         0         0   \n\n   pixel780  pixel781  pixel782  pixel783  \n0         0         0         0         0  \n1         0         0         0         0  \n2         0         0         0         0  \n3         0         0         0         0  \n4         0         0         0         0  \n\n[5 rows x 785 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>pixel0</th>\n      <th>pixel1</th>\n      <th>pixel2</th>\n      <th>pixel3</th>\n      <th>pixel4</th>\n      <th>pixel5</th>\n      <th>pixel6</th>\n      <th>pixel7</th>\n      <th>pixel8</th>\n      <th>...</th>\n      <th>pixel774</th>\n      <th>pixel775</th>\n      <th>pixel776</th>\n      <th>pixel777</th>\n      <th>pixel778</th>\n      <th>pixel779</th>\n      <th>pixel780</th>\n      <th>pixel781</th>\n      <th>pixel782</th>\n      <th>pixel783</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 785 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"The training dataset has 28x28 = 784 dimensions features and a column of label. The test dataset has 784-D data. Next we'll define Custom Dataset in order to do convert to tensor, do some transitions abd process data in mini-batches. Dataset takes two dataframe data. "},{"metadata":{"trusted":true},"cell_type":"code","source":"#CustomDatasetFromDF\nclass MNISTDataset(Dataset):\n    def __init__(self,  data, target, train=True, transform=None):\n        \"\"\"\n        Args:\n            csv_path (string): path to csv file\n            transform: pytorch transforms for transforms and tensor conversion\n        \"\"\"\n        self.train = train\n        if self.train :\n            self.data = data\n            self.labels = np.asarray(target.iloc[:])\n        else:\n            self.data = data\n            self.labels = None\n        self.height = 28 # Height of image\n        self.width = 28 # Width of image\n        self.transform = transform\n\n    def __getitem__(self, index):\n        # Read each 784 pixels and reshape the 1D array ([784]) to 2D array ([28,28])\n        img_as_np = np.asarray(self.data.iloc[index][0:]).reshape(self.height, self.width).astype('uint8')\n        # Convert image from numpy array to PIL image, mode 'L' is for grayscale\n        img_as_img = Image.fromarray(img_as_np)\n        img_as_img = img_as_img.convert('L')\n        img_as_tensor = img_as_img\n        \n        if self.train:\n            single_image_label = self.labels[index]\n        else:\n            single_image_label = None\n            \n        # Transform image to tensor\n        if self.transform is not None:\n            img_as_tensor = self.transform(img_as_img)\n        \n        if self.train:\n        # Return image and the label                \n            return (img_as_tensor, single_image_label)\n        else:\n            return img_as_tensor\n    \n    def __len__(self):\n        return len(self.data.index)","execution_count":4,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"PyTorch DataLoaders are objects that act as Python generators. They supply data in chunks or batches while training and validation.  \nOur loader will behave like an iterator, so we can loop over it and fetch a different mini-batch every time. For each \n\n### Data Augmentation\nData augmentation is a common deep learning technique where we modify images on the fly while training the neural network to see additional images flipped or rotated at different axes and angles. This usually results in better training performance since the network sees multiple views of the same image and has a better chance of identifying its class when minimizing the loss function.\nWe use following augmentation:\n* RandomRotation at a specific degree (15 in our case below) that rotates some of them randomly at an angle of 15 degree again with a probability of p which defaults to 0.5.\n\n### Data Normalization\nIn data normalization, we statistically normalize the pixel values in our images. This mostly results in better training performance and faster convergence. A common way to perform normalization is to subtract the mean of pixel values of the whole dataset from each pixel, and then divide by the standard deviation of the pixels of the whole dataset.\n\nThe values 0.1310 and 0.3085 used for the Normalize() transformation below are the global mean and standard deviation of the MNIST dataset. Following code is used to calculate mean/std dev of dataset. It take dataloader as input.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"def calculate_img_stats_full(dataset):\n    imgs_ = torch.stack([img for img,_ in dataset],dim=1)\n    imgs_ = imgs_.view(1,-1)\n    imgs_mean = imgs_.mean(dim=1)\n    imgs_std = imgs_.std(dim=1)\n    return imgs_mean,imgs_std\n\n#transformations_org = transforms.Compose([transforms.ToTensor()])\n#train_org = MNISTDataset(x, y, True, transformations_org)\n\n#calculate_img_stats_full(train_org)\n# (tensor([0.1310]), tensor([0.3085]))","execution_count":5,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we can create our datasets again from scratch with all the transformations, augmentations, and normalization appliedâ€”splitting them into train and validation, and obtaining the final DataLoaders."},{"metadata":{"trusted":true},"cell_type":"code","source":"transformations_train = transforms.Compose([transforms.RandomRotation(15),                                       \n                                            transforms.RandomAffine(0, shear=10, scale=(0.8,1.2)),\n                                            transforms.ToTensor(),\n                                            transforms.Normalize(mean=[0.1310], std=[0.3085])\n                                           ])\n\n\ntransformations_valid = transforms.Compose([transforms.ToTensor(),\n                                            transforms.Normalize(mean=[0.1310], std=[0.3085])\n                                           ])\n\ntrain = MNISTDataset(X_train, y_train, True, transformations_train)\nvalid = MNISTDataset(X_valid, y_valid, True, transformations_valid)\ntest  = MNISTDataset(data=test_df, target=None, train=False, transform=transformations_valid)","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_loader = DataLoader(train, batch_size=batch_size_train,num_workers=2, shuffle=True)\nvalid_loader = DataLoader(valid, batch_size=batch_size_test, num_workers=2, shuffle=True)\ntest_loader  = DataLoader(test,  batch_size=batch_size_test, shuffle=False)","execution_count":7,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Building the Network"},{"metadata":{"trusted":true},"cell_type":"code","source":"class Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv_block = nn.Sequential(\n            nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(32),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(64),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(128),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2) \n        )\n        \n        self.linear_block = nn.Sequential(\n            nn.Dropout(p=0.5),\n            nn.Linear(128*7*7, 128),\n            nn.BatchNorm1d(128),\n            nn.ReLU(inplace=True),\n            nn.Dropout(0.5),\n            nn.Linear(128, 64),\n            nn.BatchNorm1d(64),\n            nn.ReLU(inplace=True),\n            nn.Dropout(0.5),\n            nn.Linear(64, 10)\n        )\n\n    def forward(self, x):\n        x = self.conv_block(x)\n        x = x.view(x.size(0), -1)\n        x = self.linear_block(x)\n        return x","execution_count":8,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Training the Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"cnn_model = Net()    \ncriterion = nn.CrossEntropyLoss()\n\nif torch.cuda.is_available():\n    cnn_model.cuda()\n    criterion.cuda()                       \n\noptimizer = optim.Adam(params=cnn_model.parameters(), lr=learning_rate)    \n\nexp_lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min')\n\ntrain_losses = []\ntrain_counter = []\ntest_losses = []\ntest_counter = [i*len(train_loader.dataset) for i in range(1, num_epoch + 1)]    \n\nbest_model_wts = copy.deepcopy(cnn_model.state_dict())\nbest_acc = 0.0\n\nsince = time.time()\n\nfor epoch in range(1, num_epoch + 1):\n    cnn_model.train()    \n    for i, (images, labels) in enumerate(train_loader):\n        images = Variable(images).cuda()\n        labels = Variable(labels).cuda()\n        # Clear gradients\n        optimizer.zero_grad()\n        # Forward pass\n        outputs = cnn_model(images)\n        # Calculate loss\n        loss = criterion(outputs, labels)\n        # Backward pass\n        loss.backward()\n        # Update weights\n        optimizer.step()\n        if (i + 1)% log_interval == 0:\n            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n                epoch, (i + 1) * len(images), len(train_loader.dataset),\n                100. * (i + 1) / len(train_loader), loss.data))\n            train_losses.append(loss.item())\n            train_counter.append((i*64) + ((epoch-1)*len(train_loader.dataset)))\n    cnn_model.eval()    \n    loss = 0    \n    running_corrects = 0\n    with torch.no_grad():       \n        for i, (data, target) in enumerate(valid_loader):\n            data = Variable(data).cuda()\n            target = Variable(target).cuda()\n            output = cnn_model(data)\n            loss += F.cross_entropy(output, target, reduction='sum').item()            \n            _, preds = torch.max(output, 1)            \n            running_corrects += torch.sum(preds == target.data)\n    loss /= len(valid_loader.dataset)\n    test_losses.append(loss)\n    epoch_acc = 100. * running_corrects.double() / len(valid_loader.dataset)\n    print('\\nAverage Val Loss: {:.4f}, Val Accuracy: {}/{} ({:.3f}%)\\n'.format(\n        loss, running_corrects, len(valid_loader.dataset), epoch_acc))\n    if epoch_acc > best_acc:\n        best_acc = epoch_acc\n        best_model_wts = copy.deepcopy(cnn_model.state_dict())\n    exp_lr_scheduler.step(loss)\n             \ntime_elapsed = time.time() - since\nprint('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\nprint('Best val Acc: {:4f}'.format(best_acc))","execution_count":16,"outputs":[{"output_type":"stream","text":"Train Epoch: 1 [3200/35700 (9%)]\tLoss: 0.722314\nTrain Epoch: 1 [6400/35700 (18%)]\tLoss: 0.652657\nTrain Epoch: 1 [9600/35700 (27%)]\tLoss: 0.696196\nTrain Epoch: 1 [12800/35700 (36%)]\tLoss: 0.445753\nTrain Epoch: 1 [16000/35700 (45%)]\tLoss: 0.258333\nTrain Epoch: 1 [19200/35700 (54%)]\tLoss: 0.271636\nTrain Epoch: 1 [22400/35700 (63%)]\tLoss: 0.339841\nTrain Epoch: 1 [25600/35700 (72%)]\tLoss: 0.243227\nTrain Epoch: 1 [28800/35700 (81%)]\tLoss: 0.503460\nTrain Epoch: 1 [32000/35700 (90%)]\tLoss: 0.214893\nTrain Epoch: 1 [35200/35700 (99%)]\tLoss: 0.323193\n\nAverage Val Loss: 0.0654, Val Accuracy: 6172/6300 (97.968%)\n\nTraining complete in 0m 33s\nBest val Acc: 97.968254\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"## Evaluating the Model's Performance"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure()\nplt.plot(train_counter, train_losses, color='blue')\nplt.scatter(test_counter, test_losses, color='red')\nplt.legend(['Train Loss', 'Test Loss'], loc='upper right')\nplt.xlabel('number of training examples seen')\nplt.ylabel('negative log likelihood loss')","execution_count":10,"outputs":[{"output_type":"execute_result","execution_count":10,"data":{"text/plain":"Text(0, 0.5, 'negative log likelihood loss')"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"metadata":{},"cell_type":"markdown","source":"## Test the Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"cnn_model.eval()\ntest_preds = None\ntest_preds = torch.LongTensor()\n    \nfor i, data in enumerate(test_loader):\n    data = Variable(data).cuda()   \n    output = cnn_model(data)\n    preds = output.cpu().data.max(1, keepdim=True)[1]\n    test_preds = torch.cat((test_preds, preds), dim=0)\n","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"out_df = pd.DataFrame({'ImageId':np.arange(1, len(test_loader.dataset)+1), 'Label':test_preds.numpy().squeeze()})\nout_df.to_csv('submission.csv', index=False)","execution_count":12,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n","name":"stderr"}]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}